{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:02.103595Z",
     "start_time": "2022-10-05T03:38:56.695327Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas_profiling\n",
    "import sklearn.metrics\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.preprocessing import power_transform\n",
    "\n",
    "import lightgbm as lgbm\n",
    "import xgboost\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, classification_report, mean_squared_error, log_loss, make_scorer\n",
    "\n",
    "import optuna\n",
    "import optuna.integration.lightgbm as lgb\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 8)\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:02.165588Z",
     "start_time": "2022-10-05T03:39:02.105598Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:06.101675Z",
     "start_time": "2022-10-05T03:39:04.045517Z"
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Transported'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Transported'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m df[col\u001b[38;5;241m.\u001b[39mlower()] \u001b[38;5;241m=\u001b[39m df[col]\n\u001b[0;32m     10\u001b[0m df\u001b[38;5;241m.\u001b[39mdrop(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 11\u001b[0m df_test[col\u001b[38;5;241m.\u001b[39mlower()] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     12\u001b[0m df_test\u001b[38;5;241m.\u001b[39mdrop(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Transported'"
     ]
    }
   ],
   "source": [
    "# Делаю все названия признаков, с маленькой буквы\n",
    "for col in df.columns:\n",
    "    if col != 'Transported':\n",
    "        df[col.lower()] = df[col]\n",
    "        df_test[col.lower()] = df_test[col]\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "        df_test.drop(col, axis=1, inplace=True)\n",
    "    else:\n",
    "        df[col.lower()] = df[col]\n",
    "        df.drop(col, axis=1, inplace=True)\n",
    "        df_test[col.lower()] = df_test[col]\n",
    "        df_test.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:14.049517Z",
     "start_time": "2022-10-05T03:39:14.042510Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=[np.number]) # Список с числовыми признаками\n",
    "not_numeric_df = df.select_dtypes(exclude=[np.number]) # Список с нечисловыми признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:16.226876Z",
     "start_time": "2022-10-05T03:39:15.378505Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex2\\AppData\\Local\\Temp\\ipykernel_17856\\3375326553.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df[numeric_df.columns] = df[numeric_df.columns].fillna(df.median())\n",
      "C:\\Users\\Alex2\\AppData\\Local\\Temp\\ipykernel_17856\\3375326553.py:3: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_test[numeric_df.columns] = df_test[numeric_df.columns].fillna(df_test.median())\n"
     ]
    }
   ],
   "source": [
    "# Заменяем все пропущенные значения в числовых столбцах на медианное значение по столбцу\n",
    "df[numeric_df.columns] = df[numeric_df.columns].fillna(df.median())\n",
    "df_test[numeric_df.columns] = df_test[numeric_df.columns].fillna(df_test.median())\n",
    "\n",
    "# Заменяем все пропущенные значения в нечисловых столбцах на чаще встречающееся значение по столбцу\n",
    "not_numeric_df = not_numeric_df.drop('transported', axis=1)\n",
    "for col in not_numeric_df:\n",
    "    df[col] = df[col].fillna(df[col].describe().top)\n",
    "    df_test[col] = df_test[col].fillna(df_test[col].describe().top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:18.199658Z",
     "start_time": "2022-10-05T03:39:18.177791Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Меняем тип данных для некоторых столбцов из тренировочной и тестовой выборки\n",
    "df['cryosleep'] = df['cryosleep'].astype('bool')\n",
    "df['age'] = df['age'].astype('int')\n",
    "df['vip'] = df['vip'].astype('bool')\n",
    "\n",
    "df_test['cryosleep'] = df_test['cryosleep'].astype('bool')\n",
    "df_test['age'] = df_test['age'].astype('float64')\n",
    "df_test['vip'] = df_test['vip'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:18.871835Z",
     "start_time": "2022-10-05T03:39:18.819063Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Удаление выбросов\n",
    "for col in numeric_df:\n",
    "    low = df[col].quantile(0.25)\n",
    "    high = df[col].quantile(0.95)\n",
    "    iqr = high - low\n",
    "    df[df[col] > (high + 1.5*iqr)] = np.nan\n",
    "    df[df[col] < (low - 1.5*iqr)] = np.nan\n",
    "    df = df[~np.isnan(df[col])]\n",
    "    \n",
    "    df_test[df_test[col] > (high + 1.5*iqr)] = np.nan\n",
    "    df_test[df_test[col] < (low - 1.5*iqr)] = np.nan\n",
    "    df_test = df_test[~np.isnan(df_test[col])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:31.059690Z",
     "start_time": "2022-10-05T03:39:31.027349Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Заменя все False и True на 0 и 1\n",
    "for col in df.columns:\n",
    "    if True in df[col].values:\n",
    "        df[col] = df[col].replace({False: 0, True: 1})\n",
    "        if col != 'transported':\n",
    "            df_test[col] = df_test[col].replace({False: 0, True: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:31.075683Z",
     "start_time": "2022-10-05T03:39:31.062681Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "onehot = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:31.105939Z",
     "start_time": "2022-10-05T03:39:31.078688Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_label = label.fit_transform(df['cabin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:31.151737Z",
     "start_time": "2022-10-05T03:39:31.108913Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_label = label.fit_transform(df['cabin'])\n",
    "df_test_label = label.fit_transform(df_test['cabin'])\n",
    "df_onehot = onehot.fit_transform(df[['homeplanet', 'destination']])\n",
    "df_test_onehot = onehot.fit_transform(df_test[['homeplanet', 'destination']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:31.166869Z",
     "start_time": "2022-10-05T03:39:31.153740Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "columns_onehot = [*onehot.categories_[0], *onehot.categories_[1]]\n",
    "data_onehot = pd.DataFrame(df_onehot.toarray(), columns=columns_onehot)\n",
    "data_test_onehot = pd.DataFrame(df_test_onehot.toarray(), columns=columns_onehot)\n",
    "\n",
    "data_label = pd.DataFrame(df_label, columns=['cabine'])\n",
    "data_test_label = pd.DataFrame(df_test_label, columns=['cabine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:31.182569Z",
     "start_time": "2022-10-05T03:39:31.168681Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.drop(['cabin', 'homeplanet', 'destination'], axis=1, inplace=True)\n",
    "df_test.drop(['cabin', 'homeplanet', 'destination'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:31.214529Z",
     "start_time": "2022-10-05T03:39:31.184583Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, data_label, data_onehot], axis=1, join='inner')\n",
    "df_test = pd.concat([df_test, data_test_label, data_test_onehot], axis=1, join='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:31.230437Z",
     "start_time": "2022-10-05T03:39:31.216530Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Меняем тип данных для преобразованных категориальных признаков\n",
    "for col in ['cabine', 'Earth', 'Europa', 'Mars', '55 Cancri e', 'PSO J318.5-22', 'TRAPPIST-1e']:\n",
    "    df[col] = df[col].astype('int')\n",
    "    df_test[col] = df_test[col].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:31.246054Z",
     "start_time": "2022-10-05T03:39:31.232444Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pass_id_df_test = df_test['passengerid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:31.261833Z",
     "start_time": "2022-10-05T03:39:31.249326Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = df.drop(['name', 'passengerid', 'transported'], axis=1)\n",
    "data_test = df_test.drop('name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:31.293904Z",
     "start_time": "2022-10-05T03:39:31.263797Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Стандартизируем\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "scaler.fit_transform(data_test)\n",
    "data = pd.DataFrame(data, columns=['cryosleep', 'age', 'vip', 'roomservice',\n",
    "       'foodcourt', 'shoppingmall', 'spa', 'vrdeck',\n",
    "       'cabine', 'Earth', 'Europa', 'Mars', '55 Cancri e',\n",
    "       'PSO J318.5-22', 'TRAPPIST-1e'])\n",
    "data = data.abs()\n",
    "\n",
    "data_test = pd.DataFrame(data_test, columns=['cryosleep', 'age', 'vip', 'roomservice',\n",
    "                                   'foodcourt', 'shoppingmall', 'spa', 'vrdeck',\n",
    "                                   'cabine', 'Earth', 'Europa', 'Mars', '55 Cancri e',\n",
    "                                   'PSO J318.5-22', 'TRAPPIST-1e'])\n",
    "data_test = data_test.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:41.610238Z",
     "start_time": "2022-10-05T03:39:41.546570Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Оценка важности признаков\n",
    "bestfeatures = SelectKBest(score_func=chi2, k='all')\n",
    "fit = bestfeatures.fit(data, df['transported'])\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:41.626217Z",
     "start_time": "2022-10-05T03:39:41.611221Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "featureScores.columns = ['Specs', 'Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:41.672217Z",
     "start_time": "2022-10-05T03:39:41.627218Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_box_trans = power_transform(data[['roomservice', 'spa', 'vrdeck', 'foodcourt', 'shoppingmall']], method='box-cox')\n",
    "data[['roomservice', 'spa', 'vrdeck', 'foodcourt', 'shoppingmall']] = data_box_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-05T03:39:41.973517Z",
     "start_time": "2022-10-05T03:39:41.674221Z"
    },
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The Box-Cox transformation can only be applied to strictly positive data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_test_box_trans \u001b[38;5;241m=\u001b[39m \u001b[43mpower_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroomservice\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspa\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvrdeck\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfoodcourt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mshoppingmall\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbox-cox\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m data_test[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroomservice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspa\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvrdeck\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfoodcourt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshoppingmall\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m data_test_box_trans\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3424\u001b[0m, in \u001b[0;36mpower_transform\u001b[1;34m(X, method, standardize, copy)\u001b[0m\n\u001b[0;32m   3327\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3328\u001b[0m \u001b[38;5;124;03mPower transforms are a family of parametric, monotonic transformations\u001b[39;00m\n\u001b[0;32m   3329\u001b[0m \u001b[38;5;124;03mthat are applied to make data more Gaussian-like. This is useful for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3421\u001b[0m \u001b[38;5;124;03m       of the Royal Statistical Society B, 26, 211-252 (1964).\u001b[39;00m\n\u001b[0;32m   3422\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3423\u001b[0m pt \u001b[38;5;241m=\u001b[39m PowerTransformer(method\u001b[38;5;241m=\u001b[39mmethod, standardize\u001b[38;5;241m=\u001b[39mstandardize, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m-> 3424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3065\u001b[0m, in \u001b[0;36mPowerTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   3048\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3049\u001b[0m     \u001b[38;5;124;03m\"\"\"Fit `PowerTransformer` to `X`, then transform `X`.\u001b[39;00m\n\u001b[0;32m   3050\u001b[0m \n\u001b[0;32m   3051\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3063\u001b[0m \u001b[38;5;124;03m        Transformed data.\u001b[39;00m\n\u001b[0;32m   3064\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3065\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_transform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3068\u001b[0m, in \u001b[0;36mPowerTransformer._fit\u001b[1;34m(self, X, y, force_transform)\u001b[0m\n\u001b[0;32m   3067\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, force_transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m-> 3068\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_positive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   3070\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m force_transform:  \u001b[38;5;66;03m# if call from fit()\u001b[39;00m\n\u001b[0;32m   3071\u001b[0m         X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# force copy so that fit does not change X inplace\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3299\u001b[0m, in \u001b[0;36mPowerTransformer._check_input\u001b[1;34m(self, X, in_fit, check_positive, check_shape, check_method)\u001b[0m\n\u001b[0;32m   3297\u001b[0m     np\u001b[38;5;241m.\u001b[39mwarnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll-NaN (slice|axis) encountered\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3298\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check_positive \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbox-cox\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnanmin(X) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3299\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3300\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Box-Cox transformation can only be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3301\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplied to strictly positive data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3302\u001b[0m         )\n\u001b[0;32m   3304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_shape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambdas_):\n\u001b[0;32m   3305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput data has a different number of features \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthan fitting data. Should have \u001b[39m\u001b[38;5;132;01m{n}\u001b[39;00m\u001b[38;5;124m, data has \u001b[39m\u001b[38;5;132;01m{m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   3308\u001b[0m             n\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambdas_), m\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3309\u001b[0m         )\n\u001b[0;32m   3310\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The Box-Cox transformation can only be applied to strictly positive data"
     ]
    }
   ],
   "source": [
    "data_test_box_trans = power_transform(data_test[['roomservice', 'spa', 'vrdeck', 'foodcourt', 'shoppingmall']], method='box-cox')\n",
    "data_test[['roomservice', 'spa', 'vrdeck', 'foodcourt', 'shoppingmall']] = data_test_box_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T07:15:18.952176Z",
     "start_time": "2022-09-24T07:15:18.942985Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data, df['transported'], test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>Logistic Regression</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T07:15:20.342345Z",
     "start_time": "2022-09-24T07:15:20.326989Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def log_reg(trial, x_train, y_train):\n",
    "\n",
    "    params_grid = {\n",
    "        'penalty': trial.suggest_categorical('penalty', ['l2', 'none']),\n",
    "        'C': trial.suggest_float('C', 0.01, 0.1)\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    log = LogisticRegression(**params_grid)\n",
    "    scores = cross_validate(log, x_train, y_train, cv=cv, scoring=make_scorer(log_loss))\n",
    "\n",
    "    return np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T07:15:29.352444Z",
     "start_time": "2022-09-24T07:15:21.655993Z"
    },
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-05 03:58:05,735]\u001b[0m A new study created in memory with name: no-name-d5639da7-9a68-4bde-90b0-eafe80d44b80\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:05,812]\u001b[0m Trial 0 finished with value: 9.411650800781976 and parameters: {'penalty': 'none', 'C': 0.031247429604320094}. Best is trial 0 with value: 9.411650800781976.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:05,888]\u001b[0m Trial 1 finished with value: 9.205912364254486 and parameters: {'penalty': 'l2', 'C': 0.013654483859853652}. Best is trial 0 with value: 9.411650800781976.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:05,958]\u001b[0m Trial 2 finished with value: 9.34308916135252 and parameters: {'penalty': 'l2', 'C': 0.023650777278719434}. Best is trial 0 with value: 9.411650800781976.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:06,025]\u001b[0m Trial 3 finished with value: 9.363632323332277 and parameters: {'penalty': 'none', 'C': 0.0829544144441191}. Best is trial 0 with value: 9.411650800781976.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:06,105]\u001b[0m Trial 4 finished with value: 9.521408182766658 and parameters: {'penalty': 'none', 'C': 0.0833917749898228}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:06,187]\u001b[0m Trial 5 finished with value: 9.473410509142848 and parameters: {'penalty': 'l2', 'C': 0.040110086219340604}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:06,256]\u001b[0m Trial 6 finished with value: 9.500828812601384 and parameters: {'penalty': 'none', 'C': 0.03053379339776873}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:06,356]\u001b[0m Trial 7 finished with value: 9.480258335674657 and parameters: {'penalty': 'l2', 'C': 0.0973416070296958}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:06,439]\u001b[0m Trial 8 finished with value: 9.411650959589807 and parameters: {'penalty': 'none', 'C': 0.023392823134815943}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:06,520]\u001b[0m Trial 9 finished with value: 9.349923330410842 and parameters: {'penalty': 'l2', 'C': 0.08081637155167924}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:06,599]\u001b[0m Trial 10 finished with value: 9.473388911277803 and parameters: {'penalty': 'none', 'C': 0.056377436111841324}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:06,673]\u001b[0m Trial 11 finished with value: 9.487108703131762 and parameters: {'penalty': 'none', 'C': 0.05634598389046277}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:06,750]\u001b[0m Trial 12 finished with value: 9.466529491774319 and parameters: {'penalty': 'none', 'C': 0.07248388608954145}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:06,823]\u001b[0m Trial 13 finished with value: 9.418510379093295 and parameters: {'penalty': 'none', 'C': 0.0437316202009462}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:06,897]\u001b[0m Trial 14 finished with value: 9.473389387701296 and parameters: {'penalty': 'none', 'C': 0.06665142567747537}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:06,971]\u001b[0m Trial 15 finished with value: 9.41165111839764 and parameters: {'penalty': 'none', 'C': 0.09858560602233808}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:07,043]\u001b[0m Trial 16 finished with value: 9.500828177370057 and parameters: {'penalty': 'none', 'C': 0.042117898110594895}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:07,120]\u001b[0m Trial 17 finished with value: 9.452809223496866 and parameters: {'penalty': 'none', 'C': 0.011562643512864373}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:07,195]\u001b[0m Trial 18 finished with value: 9.480248171973455 and parameters: {'penalty': 'none', 'C': 0.08505843169391451}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:07,276]\u001b[0m Trial 19 finished with value: 9.50082849498572 and parameters: {'penalty': 'none', 'C': 0.050259083970849466}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:07,362]\u001b[0m Trial 20 finished with value: 9.370491901643593 and parameters: {'penalty': 'none', 'C': 0.06594723787635653}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:07,447]\u001b[0m Trial 21 finished with value: 9.425370910251598 and parameters: {'penalty': 'none', 'C': 0.049181981839825493}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:07,520]\u001b[0m Trial 22 finished with value: 9.521408023958827 and parameters: {'penalty': 'none', 'C': 0.031328679151888354}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:07,601]\u001b[0m Trial 23 finished with value: 9.377351479954909 and parameters: {'penalty': 'none', 'C': 0.022122200965935535}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:07,675]\u001b[0m Trial 24 finished with value: 9.397930691312357 and parameters: {'penalty': 'none', 'C': 0.03305827779626794}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:07,757]\u001b[0m Trial 25 finished with value: 9.487108385516098 and parameters: {'penalty': 'none', 'C': 0.029716929845836838}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:07,837]\u001b[0m Trial 26 finished with value: 9.43909006687423 and parameters: {'penalty': 'none', 'C': 0.09140106814282933}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:07,922]\u001b[0m Trial 27 finished with value: 9.459692781790697 and parameters: {'penalty': 'l2', 'C': 0.03736259888462689}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:07,995]\u001b[0m Trial 28 finished with value: 9.487108067900436 and parameters: {'penalty': 'none', 'C': 0.01819141478808181}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:08,071]\u001b[0m Trial 29 finished with value: 9.500828971409215 and parameters: {'penalty': 'none', 'C': 0.029516841844813735}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:08,145]\u001b[0m Trial 30 finished with value: 9.459669913463 and parameters: {'penalty': 'none', 'C': 0.06318738954187929}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:08,221]\u001b[0m Trial 31 finished with value: 9.452809541112526 and parameters: {'penalty': 'none', 'C': 0.03080364962890311}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:08,294]\u001b[0m Trial 32 finished with value: 9.439089431642905 and parameters: {'penalty': 'none', 'C': 0.027704182307973}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:08,369]\u001b[0m Trial 33 finished with value: 9.473388434854309 and parameters: {'penalty': 'none', 'C': 0.03437948716727532}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:08,437]\u001b[0m Trial 34 finished with value: 9.24020247422734 and parameters: {'penalty': 'l2', 'C': 0.017264426920946714}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:08,509]\u001b[0m Trial 35 finished with value: 9.425370433828103 and parameters: {'penalty': 'none', 'C': 0.044229954763041854}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:08,592]\u001b[0m Trial 36 finished with value: 9.500839770341736 and parameters: {'penalty': 'l2', 'C': 0.07520610339775863}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:08,674]\u001b[0m Trial 37 finished with value: 9.43910038938326 and parameters: {'penalty': 'l2', 'C': 0.08957446015093508}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:08,762]\u001b[0m Trial 38 finished with value: 9.473400504249483 and parameters: {'penalty': 'l2', 'C': 0.07382384382592322}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:08,847]\u001b[0m Trial 39 finished with value: 9.459679600740703 and parameters: {'penalty': 'l2', 'C': 0.07954973629975393}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:08,925]\u001b[0m Trial 40 finished with value: 9.507699507460885 and parameters: {'penalty': 'l2', 'C': 0.07277665799271765}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:09,005]\u001b[0m Trial 41 finished with value: 9.397942760707528 and parameters: {'penalty': 'l2', 'C': 0.07447074664509368}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:09,085]\u001b[0m Trial 42 finished with value: 9.349922059948192 and parameters: {'penalty': 'l2', 'C': 0.08982645237066475}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:09,172]\u001b[0m Trial 43 finished with value: 9.377363072926588 and parameters: {'penalty': 'l2', 'C': 0.07850868610920465}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:09,254]\u001b[0m Trial 44 finished with value: 9.46653902024419 and parameters: {'penalty': 'l2', 'C': 0.08332479089870524}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:09,331]\u001b[0m Trial 45 finished with value: 9.480263417525254 and parameters: {'penalty': 'l2', 'C': 0.05933606835030693}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:09,411]\u001b[0m Trial 46 finished with value: 9.34992444206566 and parameters: {'penalty': 'l2', 'C': 0.06976879724855624}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:09,489]\u001b[0m Trial 47 finished with value: 9.439101183422414 and parameters: {'penalty': 'l2', 'C': 0.07703282710136544}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:09,573]\u001b[0m Trial 48 finished with value: 9.452818910774571 and parameters: {'penalty': 'l2', 'C': 0.09418819040161111}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:09,660]\u001b[0m Trial 49 finished with value: 9.363642169417814 and parameters: {'penalty': 'l2', 'C': 0.08654935195716709}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:09,755]\u001b[0m Trial 50 finished with value: 9.50770554215847 and parameters: {'penalty': 'l2', 'C': 0.05166062800707098}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:09,834]\u001b[0m Trial 51 finished with value: 9.487126013185364 and parameters: {'penalty': 'l2', 'C': 0.04965942416526665}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:09,919]\u001b[0m Trial 52 finished with value: 9.452824151433 and parameters: {'penalty': 'l2', 'C': 0.06201803716242659}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:10,000]\u001b[0m Trial 53 finished with value: 9.39795371844788 and parameters: {'penalty': 'l2', 'C': 0.037897623674656995}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:10,080]\u001b[0m Trial 54 finished with value: 9.493981144877406 and parameters: {'penalty': 'l2', 'C': 0.06864739204301928}. Best is trial 4 with value: 9.521408182766658.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:10,151]\u001b[0m Trial 55 finished with value: 9.53512702177363 and parameters: {'penalty': 'none', 'C': 0.05300197417798509}. Best is trial 55 with value: 9.53512702177363.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:10,220]\u001b[0m Trial 56 finished with value: 9.5557068683624 and parameters: {'penalty': 'none', 'C': 0.05270220371229427}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:10,289]\u001b[0m Trial 57 finished with value: 9.487108861939593 and parameters: {'penalty': 'none', 'C': 0.05283210341365543}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:10,364]\u001b[0m Trial 58 finished with value: 9.432230012139422 and parameters: {'penalty': 'none', 'C': 0.05293208357204376}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:10,444]\u001b[0m Trial 59 finished with value: 9.418511014324618 and parameters: {'penalty': 'none', 'C': 0.04693092383589505}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:10,516]\u001b[0m Trial 60 finished with value: 9.459669278231676 and parameters: {'penalty': 'none', 'C': 0.05949674589333479}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:10,591]\u001b[0m Trial 61 finished with value: 9.487109814786582 and parameters: {'penalty': 'none', 'C': 0.055561404421302}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:10,667]\u001b[0m Trial 62 finished with value: 9.459669437039505 and parameters: {'penalty': 'none', 'C': 0.07114572851180304}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:10,750]\u001b[0m Trial 63 finished with value: 9.432229535715928 and parameters: {'penalty': 'none', 'C': 0.04594315773026742}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:10,833]\u001b[0m Trial 64 finished with value: 9.466529332966484 and parameters: {'penalty': 'none', 'C': 0.06339817962419286}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:10,911]\u001b[0m Trial 65 finished with value: 9.493983209379213 and parameters: {'penalty': 'l2', 'C': 0.05883695556060607}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:10,980]\u001b[0m Trial 66 finished with value: 9.473389228893463 and parameters: {'penalty': 'none', 'C': 0.08269272833942704}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:11,054]\u001b[0m Trial 67 finished with value: 9.493967963827416 and parameters: {'penalty': 'none', 'C': 0.041303905146776856}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:11,136]\u001b[0m Trial 68 finished with value: 9.432243510805074 and parameters: {'penalty': 'l2', 'C': 0.0662696592512472}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:11,208]\u001b[0m Trial 69 finished with value: 9.535127339389291 and parameters: {'penalty': 'none', 'C': 0.07649082459073636}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:11,284]\u001b[0m Trial 70 finished with value: 9.466529015350824 and parameters: {'penalty': 'none', 'C': 0.09438522570327867}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:11,356]\u001b[0m Trial 71 finished with value: 9.480249601243937 and parameters: {'penalty': 'none', 'C': 0.07627829878271576}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:11,430]\u001b[0m Trial 72 finished with value: 9.466528856542993 and parameters: {'penalty': 'none', 'C': 0.05222732671421362}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:11,501]\u001b[0m Trial 73 finished with value: 9.452810493959515 and parameters: {'penalty': 'none', 'C': 0.08660880780612923}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:11,576]\u001b[0m Trial 74 finished with value: 9.466528856542993 and parameters: {'penalty': 'none', 'C': 0.08126244058408418}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:11,649]\u001b[0m Trial 75 finished with value: 9.487108544323931 and parameters: {'penalty': 'none', 'C': 0.07337092528411418}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:11,720]\u001b[0m Trial 76 finished with value: 9.45966896061601 and parameters: {'penalty': 'none', 'C': 0.026827059093068227}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 03:58:11,800]\u001b[0m Trial 77 finished with value: 9.473401139480808 and parameters: {'penalty': 'l2', 'C': 0.06795171458976879}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:11,871]\u001b[0m Trial 78 finished with value: 9.541987870547596 and parameters: {'penalty': 'none', 'C': 0.06420481458389041}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:11,945]\u001b[0m Trial 79 finished with value: 9.425370116212441 and parameters: {'penalty': 'none', 'C': 0.06458650891693254}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:12,014]\u001b[0m Trial 80 finished with value: 9.52140834157449 and parameters: {'penalty': 'none', 'C': 0.05689579331912872}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:12,086]\u001b[0m Trial 81 finished with value: 9.5076883909127 and parameters: {'penalty': 'none', 'C': 0.05785504935520756}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:12,157]\u001b[0m Trial 82 finished with value: 9.439090225682062 and parameters: {'penalty': 'none', 'C': 0.0616778950818016}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:12,230]\u001b[0m Trial 83 finished with value: 9.466529332966484 and parameters: {'penalty': 'none', 'C': 0.05350557892477152}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:12,305]\u001b[0m Trial 84 finished with value: 9.493969234290065 and parameters: {'penalty': 'none', 'C': 0.0477107999951839}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:12,380]\u001b[0m Trial 85 finished with value: 9.41851117313245 and parameters: {'penalty': 'none', 'C': 0.05657480969822177}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:12,559]\u001b[0m Trial 86 finished with value: 9.473389228893465 and parameters: {'penalty': 'none', 'C': 0.07132482029286955}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:12,634]\u001b[0m Trial 87 finished with value: 9.439089590450738 and parameters: {'penalty': 'none', 'C': 0.060816061060633114}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:12,707]\u001b[0m Trial 88 finished with value: 9.466529650582148 and parameters: {'penalty': 'none', 'C': 0.05152071582894689}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:12,774]\u001b[0m Trial 89 finished with value: 9.439090384489893 and parameters: {'penalty': 'none', 'C': 0.07910623348548201}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:12,847]\u001b[0m Trial 90 finished with value: 9.487109020747425 and parameters: {'penalty': 'none', 'C': 0.04295479061353362}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:12,918]\u001b[0m Trial 91 finished with value: 9.487109179555256 and parameters: {'penalty': 'none', 'C': 0.057587239677106994}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:12,995]\u001b[0m Trial 92 finished with value: 9.39107158942453 and parameters: {'penalty': 'none', 'C': 0.05569072898671356}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:13,070]\u001b[0m Trial 93 finished with value: 9.40479122247066 and parameters: {'penalty': 'none', 'C': 0.04928737103340652}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:13,150]\u001b[0m Trial 94 finished with value: 9.548847448858911 and parameters: {'penalty': 'none', 'C': 0.054324651858574276}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:13,226]\u001b[0m Trial 95 finished with value: 9.452809382304695 and parameters: {'penalty': 'none', 'C': 0.020492261338032662}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:13,302]\u001b[0m Trial 96 finished with value: 9.45281001753602 and parameters: {'penalty': 'none', 'C': 0.038400827821980316}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:13,381]\u001b[0m Trial 97 finished with value: 9.43222985333159 and parameters: {'penalty': 'none', 'C': 0.06457674059633749}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:13,463]\u001b[0m Trial 98 finished with value: 9.480249124820444 and parameters: {'penalty': 'none', 'C': 0.04455093691886558}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:58:13,541]\u001b[0m Trial 99 finished with value: 9.466529174158655 and parameters: {'penalty': 'none', 'C': 0.054649855502737724}. Best is trial 56 with value: 9.5557068683624.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "func = (lambda trial: log_reg(trial, x_train, y_train))\n",
    "study.optimize(func, n_trials=100)\n",
    "model_scores = []\n",
    "model_scores.append(study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>KNN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T07:15:35.519548Z",
     "start_time": "2022-09-24T07:15:35.511545Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def knn_obj(trial, x, y):\n",
    "\n",
    "    params_grid = {\n",
    "        'n_neighbors': trial.suggest_int('n_neighbors', 1, 10),\n",
    "        'weights': trial.suggest_categorical('weights', ['uniform', 'distance'])\n",
    "    }\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    knn = KNeighborsClassifier(**params_grid)\n",
    "    scores = cross_validate(knn, x_train, y_train, scoring=make_scorer(roc_auc_score), cv=cv)\n",
    "\n",
    "    return np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T07:16:23.772212Z",
     "start_time": "2022-09-24T07:15:36.014664Z"
    },
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-05 02:46:29,081]\u001b[0m A new study created in memory with name: no-name-f6f82bfd-6163-4f38-b57c-c331174555ec\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:29,555]\u001b[0m Trial 0 finished with value: 0.7221369358535324 and parameters: {'n_neighbors': 6, 'weights': 'uniform'}. Best is trial 0 with value: 0.7221369358535324.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:29,935]\u001b[0m Trial 1 finished with value: 0.7000878543589801 and parameters: {'n_neighbors': 4, 'weights': 'distance'}. Best is trial 0 with value: 0.7221369358535324.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:30,337]\u001b[0m Trial 2 finished with value: 0.7239025158832345 and parameters: {'n_neighbors': 10, 'weights': 'distance'}. Best is trial 2 with value: 0.7239025158832345.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:30,673]\u001b[0m Trial 3 finished with value: 0.6674504000091035 and parameters: {'n_neighbors': 1, 'weights': 'distance'}. Best is trial 2 with value: 0.7239025158832345.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:31,063]\u001b[0m Trial 4 finished with value: 0.7257364936770874 and parameters: {'n_neighbors': 8, 'weights': 'distance'}. Best is trial 4 with value: 0.7257364936770874.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:31,441]\u001b[0m Trial 5 finished with value: 0.6989093307712528 and parameters: {'n_neighbors': 4, 'weights': 'distance'}. Best is trial 4 with value: 0.7257364936770874.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:31,905]\u001b[0m Trial 6 finished with value: 0.7110932094314075 and parameters: {'n_neighbors': 3, 'weights': 'uniform'}. Best is trial 4 with value: 0.7257364936770874.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:32,345]\u001b[0m Trial 7 finished with value: 0.6688974265555874 and parameters: {'n_neighbors': 2, 'weights': 'uniform'}. Best is trial 4 with value: 0.7257364936770874.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:32,844]\u001b[0m Trial 8 finished with value: 0.7367749348568522 and parameters: {'n_neighbors': 8, 'weights': 'uniform'}. Best is trial 8 with value: 0.7367749348568522.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:33,303]\u001b[0m Trial 9 finished with value: 0.7352085149704417 and parameters: {'n_neighbors': 7, 'weights': 'uniform'}. Best is trial 8 with value: 0.7367749348568522.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:33,777]\u001b[0m Trial 10 finished with value: 0.744760298486782 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:34,259]\u001b[0m Trial 11 finished with value: 0.7397022448613562 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:34,733]\u001b[0m Trial 12 finished with value: 0.7379026802548253 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:35,203]\u001b[0m Trial 13 finished with value: 0.7385547541666649 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:35,672]\u001b[0m Trial 14 finished with value: 0.7396435638621052 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:36,136]\u001b[0m Trial 15 finished with value: 0.7376231001461852 and parameters: {'n_neighbors': 8, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:36,601]\u001b[0m Trial 16 finished with value: 0.7250830824703913 and parameters: {'n_neighbors': 6, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:37,072]\u001b[0m Trial 17 finished with value: 0.7377213534829433 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:37,534]\u001b[0m Trial 18 finished with value: 0.7373374894860234 and parameters: {'n_neighbors': 7, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:38,006]\u001b[0m Trial 19 finished with value: 0.740560069328309 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:38,474]\u001b[0m Trial 20 finished with value: 0.7421358368387535 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:38,946]\u001b[0m Trial 21 finished with value: 0.73901655358101 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:39,414]\u001b[0m Trial 22 finished with value: 0.7432286487811444 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:39,876]\u001b[0m Trial 23 finished with value: 0.730536752980224 and parameters: {'n_neighbors': 7, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:40,344]\u001b[0m Trial 24 finished with value: 0.7336386731271237 and parameters: {'n_neighbors': 8, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:40,794]\u001b[0m Trial 25 finished with value: 0.7261325328347512 and parameters: {'n_neighbors': 5, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:41,265]\u001b[0m Trial 26 finished with value: 0.7372825113401013 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:41,658]\u001b[0m Trial 27 finished with value: 0.7261109908876769 and parameters: {'n_neighbors': 10, 'weights': 'distance'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:42,125]\u001b[0m Trial 28 finished with value: 0.7319515135706628 and parameters: {'n_neighbors': 7, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:42,580]\u001b[0m Trial 29 finished with value: 0.7260739683026058 and parameters: {'n_neighbors': 5, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:43,046]\u001b[0m Trial 30 finished with value: 0.7339104668933726 and parameters: {'n_neighbors': 8, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:43,518]\u001b[0m Trial 31 finished with value: 0.7441114411301061 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:43,991]\u001b[0m Trial 32 finished with value: 0.7398245911525226 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:44,468]\u001b[0m Trial 33 finished with value: 0.7411566980462003 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:44,842]\u001b[0m Trial 34 finished with value: 0.7160725546848385 and parameters: {'n_neighbors': 6, 'weights': 'distance'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:45,231]\u001b[0m Trial 35 finished with value: 0.7266512190324935 and parameters: {'n_neighbors': 9, 'weights': 'distance'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:45,693]\u001b[0m Trial 36 finished with value: 0.7320091675611959 and parameters: {'n_neighbors': 8, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:46,090]\u001b[0m Trial 37 finished with value: 0.7254944127262222 and parameters: {'n_neighbors': 10, 'weights': 'distance'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:46,566]\u001b[0m Trial 38 finished with value: 0.7429523576101981 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 10 with value: 0.744760298486782.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:47,040]\u001b[0m Trial 39 finished with value: 0.7470023997193125 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 39 with value: 0.7470023997193125.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:47,367]\u001b[0m Trial 40 finished with value: 0.6711036428561422 and parameters: {'n_neighbors': 1, 'weights': 'distance'}. Best is trial 39 with value: 0.7470023997193125.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:47,836]\u001b[0m Trial 41 finished with value: 0.7508930921270341 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:48,315]\u001b[0m Trial 42 finished with value: 0.7412445224633084 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:48,790]\u001b[0m Trial 43 finished with value: 0.7408833680084306 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:49,219]\u001b[0m Trial 44 finished with value: 0.6712969010373346 and parameters: {'n_neighbors': 2, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:49,692]\u001b[0m Trial 45 finished with value: 0.7417022409234855 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:50,155]\u001b[0m Trial 46 finished with value: 0.7404445393933916 and parameters: {'n_neighbors': 8, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:50,632]\u001b[0m Trial 47 finished with value: 0.7459748995831685 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:51,113]\u001b[0m Trial 48 finished with value: 0.7443479008521567 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:51,593]\u001b[0m Trial 49 finished with value: 0.7428837486968698 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:52,067]\u001b[0m Trial 50 finished with value: 0.7409943314565025 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:52,539]\u001b[0m Trial 51 finished with value: 0.7441065340889768 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:53,015]\u001b[0m Trial 52 finished with value: 0.7406354799030281 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:53,486]\u001b[0m Trial 53 finished with value: 0.7414317966120569 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:53,961]\u001b[0m Trial 54 finished with value: 0.7462292770183392 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:54,434]\u001b[0m Trial 55 finished with value: 0.7442437551281731 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:54,878]\u001b[0m Trial 56 finished with value: 0.7102176392727853 and parameters: {'n_neighbors': 4, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:55,353]\u001b[0m Trial 57 finished with value: 0.7483047661647471 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:55,825]\u001b[0m Trial 58 finished with value: 0.736227370677328 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:56,207]\u001b[0m Trial 59 finished with value: 0.7247679897831808 and parameters: {'n_neighbors': 8, 'weights': 'distance'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:56,646]\u001b[0m Trial 60 finished with value: 0.7102881183986047 and parameters: {'n_neighbors': 3, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:57,120]\u001b[0m Trial 61 finished with value: 0.7432987441465336 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:57,600]\u001b[0m Trial 62 finished with value: 0.7400011062429929 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:58,075]\u001b[0m Trial 63 finished with value: 0.7397344627673476 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:58,548]\u001b[0m Trial 64 finished with value: 0.7435415051267538 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:59,033]\u001b[0m Trial 65 finished with value: 0.7407768720984776 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:59,509]\u001b[0m Trial 66 finished with value: 0.7385104385522488 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:46:59,976]\u001b[0m Trial 67 finished with value: 0.740731225037031 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:00,455]\u001b[0m Trial 68 finished with value: 0.7359001242379375 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:00,934]\u001b[0m Trial 69 finished with value: 0.738347322750656 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:01,413]\u001b[0m Trial 70 finished with value: 0.740365668436781 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:01,885]\u001b[0m Trial 71 finished with value: 0.7410373750684176 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:02,358]\u001b[0m Trial 72 finished with value: 0.7343155829809718 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:02,833]\u001b[0m Trial 73 finished with value: 0.7449361999069157 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:03,300]\u001b[0m Trial 74 finished with value: 0.7412796912876043 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:03,774]\u001b[0m Trial 75 finished with value: 0.7367660261585747 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:04,164]\u001b[0m Trial 76 finished with value: 0.7323904298528927 and parameters: {'n_neighbors': 10, 'weights': 'distance'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:04,633]\u001b[0m Trial 77 finished with value: 0.7400325032322038 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:05,105]\u001b[0m Trial 78 finished with value: 0.7430868342998886 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:05,574]\u001b[0m Trial 79 finished with value: 0.7417747431962443 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:06,025]\u001b[0m Trial 80 finished with value: 0.7297869030949159 and parameters: {'n_neighbors': 5, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:06,502]\u001b[0m Trial 81 finished with value: 0.7454096639517545 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:06,978]\u001b[0m Trial 82 finished with value: 0.7418505275047567 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:07,739]\u001b[0m Trial 83 finished with value: 0.7372794457993916 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:08,218]\u001b[0m Trial 84 finished with value: 0.7415128711197776 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:08,694]\u001b[0m Trial 85 finished with value: 0.7393467660225822 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:09,164]\u001b[0m Trial 86 finished with value: 0.7342104716504408 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:09,550]\u001b[0m Trial 87 finished with value: 0.7274097204497831 and parameters: {'n_neighbors': 8, 'weights': 'distance'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:10,022]\u001b[0m Trial 88 finished with value: 0.7438964893850342 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:10,491]\u001b[0m Trial 89 finished with value: 0.7349767408250789 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:10,963]\u001b[0m Trial 90 finished with value: 0.7376196999994092 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:11,442]\u001b[0m Trial 91 finished with value: 0.7445252240217982 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:11,915]\u001b[0m Trial 92 finished with value: 0.745470897225787 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:12,394]\u001b[0m Trial 93 finished with value: 0.7422087001959313 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:12,868]\u001b[0m Trial 94 finished with value: 0.7440344935936718 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:13,343]\u001b[0m Trial 95 finished with value: 0.7428117383693184 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:13,810]\u001b[0m Trial 96 finished with value: 0.7355529134718903 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:14,285]\u001b[0m Trial 97 finished with value: 0.7451640670646531 and parameters: {'n_neighbors': 10, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:14,751]\u001b[0m Trial 98 finished with value: 0.7452524621467351 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:15,220]\u001b[0m Trial 99 finished with value: 0.7352952220889036 and parameters: {'n_neighbors': 9, 'weights': 'uniform'}. Best is trial 41 with value: 0.7508930921270341.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "func = (lambda trial: knn_obj(trial, x_train, y_train))\n",
    "study.optimize(func, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T07:20:33.163763Z",
     "start_time": "2022-09-24T07:20:33.151757Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.730731128849081, 0.7508930921270341]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores.append(study.best_value)\n",
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>SVM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T07:20:36.971683Z",
     "start_time": "2022-09-24T07:20:36.959409Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def svc_obj(trial, x, y):\n",
    "\n",
    "    params_grid = {\n",
    "        'C': trial.suggest_float('C', 0.01, 1),\n",
    "        'kernel': trial.suggest_categorical('kernel', ['linear', 'rbf', 'sigmoid']),\n",
    "        'gamma': trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
    "    }\n",
    "\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    svc = SVC(**params_grid)\n",
    "    scores = cross_validate(svc, x_train, y_train, scoring=make_scorer(roc_auc_score), cv=cv)\n",
    "\n",
    "    return np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T07:27:41.283075Z",
     "start_time": "2022-09-24T07:20:37.623163Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-05 02:47:20,386]\u001b[0m A new study created in memory with name: no-name-33a5e28b-4453-44ae-8e69-bcbf79c8db17\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:24,749]\u001b[0m Trial 0 finished with value: 0.7584800458831957 and parameters: {'C': 0.6320673538527167, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.7584800458831957.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:27,463]\u001b[0m Trial 1 finished with value: 0.7310348359700678 and parameters: {'C': 0.05304272264760601, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.7584800458831957.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:31,741]\u001b[0m Trial 2 finished with value: 0.7556015177637797 and parameters: {'C': 0.9112141769170116, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.7584800458831957.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:35,969]\u001b[0m Trial 3 finished with value: 0.7511875206182917 and parameters: {'C': 0.3284561216887394, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.7584800458831957.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:39,763]\u001b[0m Trial 4 finished with value: 0.5146744056341397 and parameters: {'C': 0.6909260751505437, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.7584800458831957.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:43,776]\u001b[0m Trial 5 finished with value: 0.5537958563220023 and parameters: {'C': 0.20414175086196282, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 0 with value: 0.7584800458831957.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:46,691]\u001b[0m Trial 6 finished with value: 0.7348115749966264 and parameters: {'C': 0.14178218047990726, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 0 with value: 0.7584800458831957.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:49,311]\u001b[0m Trial 7 finished with value: 0.7301525491945082 and parameters: {'C': 0.06491277223115878, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 0 with value: 0.7584800458831957.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:53,046]\u001b[0m Trial 8 finished with value: 0.7328485605596897 and parameters: {'C': 0.3448286462354034, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.7584800458831957.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:47:57,953]\u001b[0m Trial 9 finished with value: 0.7358300788676939 and parameters: {'C': 0.7392705180954882, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 0 with value: 0.7584800458831957.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:48:02,151]\u001b[0m Trial 10 finished with value: 0.7582138957205968 and parameters: {'C': 0.5204299293400546, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.7584800458831957.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:48:06,341]\u001b[0m Trial 11 finished with value: 0.7533298161923947 and parameters: {'C': 0.5684729630021834, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.7584800458831957.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:48:10,522]\u001b[0m Trial 12 finished with value: 0.7517971261510196 and parameters: {'C': 0.5020067252601949, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.7584800458831957.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:48:14,713]\u001b[0m Trial 13 finished with value: 0.7537497680132372 and parameters: {'C': 0.48537122285981893, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 0 with value: 0.7584800458831957.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:48:18,898]\u001b[0m Trial 14 finished with value: 0.7586296781294946 and parameters: {'C': 0.8533563545875337, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:48:23,083]\u001b[0m Trial 15 finished with value: 0.7581370474340641 and parameters: {'C': 0.9692461236274575, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:48:27,264]\u001b[0m Trial 16 finished with value: 0.7573595328025907 and parameters: {'C': 0.8190547602894896, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:48:30,928]\u001b[0m Trial 17 finished with value: 0.5921971769422729 and parameters: {'C': 0.6590313838456838, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:48:35,118]\u001b[0m Trial 18 finished with value: 0.7549882566622887 and parameters: {'C': 0.8564762011443923, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:48:39,344]\u001b[0m Trial 19 finished with value: 0.7526384553320052 and parameters: {'C': 0.7941911620966838, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:48:42,889]\u001b[0m Trial 20 finished with value: 0.5804315282821862 and parameters: {'C': 0.9901009629349999, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:48:47,316]\u001b[0m Trial 21 finished with value: 0.7560129479471575 and parameters: {'C': 0.602537094065037, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:48:51,515]\u001b[0m Trial 22 finished with value: 0.7510364818945968 and parameters: {'C': 0.3986909764759373, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:48:55,804]\u001b[0m Trial 23 finished with value: 0.7561110591164942 and parameters: {'C': 0.6014312735317905, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:49:00,180]\u001b[0m Trial 24 finished with value: 0.7580001833883188 and parameters: {'C': 0.7343648587587167, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:49:04,495]\u001b[0m Trial 25 finished with value: 0.7545147938848968 and parameters: {'C': 0.422766266736126, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:49:08,688]\u001b[0m Trial 26 finished with value: 0.7551428970443187 and parameters: {'C': 0.5466188057666987, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:49:12,960]\u001b[0m Trial 27 finished with value: 0.7547134876578073 and parameters: {'C': 0.6617759971230387, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:49:17,323]\u001b[0m Trial 28 finished with value: 0.7562664430633771 and parameters: {'C': 0.8816238183378615, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:49:22,718]\u001b[0m Trial 29 finished with value: 0.624631245617864 and parameters: {'C': 0.24220579675092058, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:49:28,254]\u001b[0m Trial 30 finished with value: 0.7352732380913759 and parameters: {'C': 0.7550277705364521, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:49:32,962]\u001b[0m Trial 31 finished with value: 0.7570264705373159 and parameters: {'C': 0.9995389487672874, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:49:37,338]\u001b[0m Trial 32 finished with value: 0.7574002620307836 and parameters: {'C': 0.9349771117387755, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:49:41,885]\u001b[0m Trial 33 finished with value: 0.7546633786927346 and parameters: {'C': 0.92414282303367, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:49:46,198]\u001b[0m Trial 34 finished with value: 0.7535648671154875 and parameters: {'C': 0.8086512189948778, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:49:50,541]\u001b[0m Trial 35 finished with value: 0.7545221580418742 and parameters: {'C': 0.9507736987021073, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:49:54,753]\u001b[0m Trial 36 finished with value: 0.7550879074160777 and parameters: {'C': 0.8648767252076831, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:49:58,402]\u001b[0m Trial 37 finished with value: 0.5316099171942347 and parameters: {'C': 0.4642310522507192, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 14 with value: 0.7586296781294946.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:50:02,626]\u001b[0m Trial 38 finished with value: 0.7592768079305111 and parameters: {'C': 0.6855149777523759, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 38 with value: 0.7592768079305111.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:50:07,438]\u001b[0m Trial 39 finished with value: 0.7362880711215686 and parameters: {'C': 0.6881343732556899, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 38 with value: 0.7592768079305111.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:50:11,641]\u001b[0m Trial 40 finished with value: 0.7577679543674426 and parameters: {'C': 0.631348623821522, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 38 with value: 0.7592768079305111.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:50:15,822]\u001b[0m Trial 41 finished with value: 0.7558658597058606 and parameters: {'C': 0.5477478119099858, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 38 with value: 0.7592768079305111.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:50:20,027]\u001b[0m Trial 42 finished with value: 0.759752425029355 and parameters: {'C': 0.7219676580881864, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:50:24,251]\u001b[0m Trial 43 finished with value: 0.7581101613773534 and parameters: {'C': 0.7173968287366137, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:50:28,465]\u001b[0m Trial 44 finished with value: 0.7585775051454469 and parameters: {'C': 0.7759626870119903, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:50:33,373]\u001b[0m Trial 45 finished with value: 0.7352206575163804 and parameters: {'C': 0.7780653415604653, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:50:37,913]\u001b[0m Trial 46 finished with value: 0.7581893348397333 and parameters: {'C': 0.8366520591738689, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:50:42,329]\u001b[0m Trial 47 finished with value: 0.759351597832562 and parameters: {'C': 0.7005680769525569, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:50:46,555]\u001b[0m Trial 48 finished with value: 0.75808569458876 and parameters: {'C': 0.693770659207907, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:50:50,043]\u001b[0m Trial 49 finished with value: 0.5078332674034897 and parameters: {'C': 0.8992256502719727, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:50:54,245]\u001b[0m Trial 50 finished with value: 0.7578294270007649 and parameters: {'C': 0.7840476498810943, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:50:58,436]\u001b[0m Trial 51 finished with value: 0.7557276954349528 and parameters: {'C': 0.6347608407825078, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:51:02,622]\u001b[0m Trial 52 finished with value: 0.7557638183834772 and parameters: {'C': 0.7092947021013047, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:51:06,809]\u001b[0m Trial 53 finished with value: 0.7569878016386974 and parameters: {'C': 0.761525473653792, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:51:10,999]\u001b[0m Trial 54 finished with value: 0.7561850504766001 and parameters: {'C': 0.6140249571095404, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:51:15,669]\u001b[0m Trial 55 finished with value: 0.7312880783999783 and parameters: {'C': 0.6639238487407337, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:51:19,856]\u001b[0m Trial 56 finished with value: 0.7583225818546404 and parameters: {'C': 0.8247512886578421, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:51:24,052]\u001b[0m Trial 57 finished with value: 0.7543758191128642 and parameters: {'C': 0.5698451383324985, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 42 with value: 0.759752425029355.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:51:28,270]\u001b[0m Trial 58 finished with value: 0.7600148787637041 and parameters: {'C': 0.7315392895389446, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:51:32,481]\u001b[0m Trial 59 finished with value: 0.7584121209897989 and parameters: {'C': 0.7393318221903401, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:51:36,684]\u001b[0m Trial 60 finished with value: 0.7599358690529954 and parameters: {'C': 0.8483783610862073, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:51:40,885]\u001b[0m Trial 61 finished with value: 0.7553306537014397 and parameters: {'C': 0.8574010205599885, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:51:45,079]\u001b[0m Trial 62 finished with value: 0.7559684454156488 and parameters: {'C': 0.7884730761706712, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:51:49,281]\u001b[0m Trial 63 finished with value: 0.757118594060102 and parameters: {'C': 0.8312284320072248, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:51:53,497]\u001b[0m Trial 64 finished with value: 0.7567895295617909 and parameters: {'C': 0.8842728623813088, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:51:57,179]\u001b[0m Trial 65 finished with value: 0.5139217973946616 and parameters: {'C': 0.736442385954011, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:01,401]\u001b[0m Trial 66 finished with value: 0.7543479611249192 and parameters: {'C': 0.6716517202735577, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:05,623]\u001b[0m Trial 67 finished with value: 0.758337442397222 and parameters: {'C': 0.9083182756542431, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:09,817]\u001b[0m Trial 68 finished with value: 0.7539764392529538 and parameters: {'C': 0.7600548768309202, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:13,991]\u001b[0m Trial 69 finished with value: 0.7547326307665079 and parameters: {'C': 0.8042290771733835, 'kernel': 'rbf', 'gamma': 'auto'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:18,306]\u001b[0m Trial 70 finished with value: 0.7386582472055261 and parameters: {'C': 0.08558632417632606, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:22,502]\u001b[0m Trial 71 finished with value: 0.7561793090912795 and parameters: {'C': 0.7157725492074029, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:26,672]\u001b[0m Trial 72 finished with value: 0.7584528028330342 and parameters: {'C': 0.5707028378014614, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:30,884]\u001b[0m Trial 73 finished with value: 0.7573184330531442 and parameters: {'C': 0.6313948387268962, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:35,319]\u001b[0m Trial 74 finished with value: 0.7358843780509243 and parameters: {'C': 0.6900883479837251, 'kernel': 'linear', 'gamma': 'auto'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:39,544]\u001b[0m Trial 75 finished with value: 0.757056713835832 and parameters: {'C': 0.8508707598126641, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:43,737]\u001b[0m Trial 76 finished with value: 0.7557377278569556 and parameters: {'C': 0.770333192702898, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:47,143]\u001b[0m Trial 77 finished with value: 0.5915024024073045 and parameters: {'C': 0.6482828400972813, 'kernel': 'sigmoid', 'gamma': 'auto'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:51,367]\u001b[0m Trial 78 finished with value: 0.7588667368395724 and parameters: {'C': 0.9560409191053044, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:55,605]\u001b[0m Trial 79 finished with value: 0.7584549776846214 and parameters: {'C': 0.961595114158803, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:52:59,830]\u001b[0m Trial 80 finished with value: 0.7592818940958147 and parameters: {'C': 0.9356620266662001, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:53:04,062]\u001b[0m Trial 81 finished with value: 0.7596651618403858 and parameters: {'C': 0.9717328569229906, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 58 with value: 0.7600148787637041.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:53:08,298]\u001b[0m Trial 82 finished with value: 0.7600502658273525 and parameters: {'C': 0.986483510719118, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 82 with value: 0.7600502658273525.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:53:12,525]\u001b[0m Trial 83 finished with value: 0.7549150080889988 and parameters: {'C': 0.9993794614563145, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 82 with value: 0.7600502658273525.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:53:16,756]\u001b[0m Trial 84 finished with value: 0.7602830303886007 and parameters: {'C': 0.9458687830996403, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 84 with value: 0.7602830303886007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:53:20,972]\u001b[0m Trial 85 finished with value: 0.7581140900621692 and parameters: {'C': 0.923624118156569, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 84 with value: 0.7602830303886007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:53:25,176]\u001b[0m Trial 86 finished with value: 0.7591850011189426 and parameters: {'C': 0.9676477290099736, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 84 with value: 0.7602830303886007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:53:29,375]\u001b[0m Trial 87 finished with value: 0.7541611162643089 and parameters: {'C': 0.9150547354523307, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 84 with value: 0.7602830303886007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:53:33,578]\u001b[0m Trial 88 finished with value: 0.7582626422802995 and parameters: {'C': 0.943275175836977, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 84 with value: 0.7602830303886007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:53:38,595]\u001b[0m Trial 89 finished with value: 0.7366574905370257 and parameters: {'C': 0.8847483160025377, 'kernel': 'linear', 'gamma': 'scale'}. Best is trial 84 with value: 0.7602830303886007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:53:42,870]\u001b[0m Trial 90 finished with value: 0.7579527241032286 and parameters: {'C': 0.9712237748529458, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 84 with value: 0.7602830303886007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:53:47,121]\u001b[0m Trial 91 finished with value: 0.7563184222283921 and parameters: {'C': 0.9720680646362478, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 84 with value: 0.7602830303886007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:53:51,362]\u001b[0m Trial 92 finished with value: 0.7557708419861704 and parameters: {'C': 0.9858181805939945, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 84 with value: 0.7602830303886007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:53:55,606]\u001b[0m Trial 93 finished with value: 0.7578480780638663 and parameters: {'C': 0.9371275483352436, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 84 with value: 0.7602830303886007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:53:59,845]\u001b[0m Trial 94 finished with value: 0.7579229338355257 and parameters: {'C': 0.9728865578888883, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 84 with value: 0.7602830303886007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:54:04,072]\u001b[0m Trial 95 finished with value: 0.7576726098220553 and parameters: {'C': 0.9039984191076776, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 84 with value: 0.7602830303886007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:54:08,307]\u001b[0m Trial 96 finished with value: 0.7585074775947583 and parameters: {'C': 0.9480113582893239, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 84 with value: 0.7602830303886007.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:54:12,537]\u001b[0m Trial 97 finished with value: 0.7609686755514365 and parameters: {'C': 0.8718633457471661, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 97 with value: 0.7609686755514365.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:54:16,048]\u001b[0m Trial 98 finished with value: 0.5046667553729134 and parameters: {'C': 0.8941990627738241, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 97 with value: 0.7609686755514365.\u001b[0m\n",
      "\u001b[32m[I 2022-10-05 02:54:20,278]\u001b[0m Trial 99 finished with value: 0.7570685504877762 and parameters: {'C': 0.873977554835951, 'kernel': 'rbf', 'gamma': 'scale'}. Best is trial 97 with value: 0.7609686755514365.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "funcq = (lambda trial: svc_obj(trial, x_train, y_train))\n",
    "study.optimize(funcq, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T07:27:41.299181Z",
     "start_time": "2022-09-24T07:27:41.286061Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_scores.append(study.best_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>Random Forest</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T07:27:41.314483Z",
     "start_time": "2022-09-24T07:27:41.301295Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def rf_obj(trial, x, y):\n",
    "\n",
    "    params_grid = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000, step=100),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['log2', 'sqrt']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 15),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 2, 50, step=10)\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier(**params_grid)\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    scores = cross_validate(rf, x, y, scoring=make_scorer(roc_auc_score), cv=cv)\n",
    "\n",
    "    return np.mean(scores['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T07:42:03.428725Z",
     "start_time": "2022-09-24T07:27:41.316482Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-10-05 02:54:44,595]\u001b[0m A new study created in memory with name: no-name-7d35eb69-11bb-4c56-aefb-fb5dc00219b7\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:54:58,216]\u001b[0m Trial 0 finished with value: 0.7658831864497534 and parameters: {'n_estimators': 1000, 'max_features': 'sqrt', 'max_depth': 12, 'min_samples_leaf': 12}. Best is trial 0 with value: 0.7658831864497534.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:55:01,673]\u001b[0m Trial 1 finished with value: 0.7670106675787067 and parameters: {'n_estimators': 300, 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_leaf': 32}. Best is trial 1 with value: 0.7670106675787067.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:55:08,211]\u001b[0m Trial 2 finished with value: 0.7667710495915152 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_leaf': 42}. Best is trial 1 with value: 0.7670106675787067.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:55:15,836]\u001b[0m Trial 3 finished with value: 0.7689548185484663 and parameters: {'n_estimators': 600, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 22}. Best is trial 3 with value: 0.7689548185484663.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:55:25,041]\u001b[0m Trial 4 finished with value: 0.7652780170199438 and parameters: {'n_estimators': 800, 'max_features': 'log2', 'max_depth': 14, 'min_samples_leaf': 42}. Best is trial 3 with value: 0.7689548185484663.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:55:33,279]\u001b[0m Trial 5 finished with value: 0.7726193016947084 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:55:42,976]\u001b[0m Trial 6 finished with value: 0.7657682758322146 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 6, 'min_samples_leaf': 32}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:55:48,659]\u001b[0m Trial 7 finished with value: 0.7650723976267946 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_leaf': 22}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:55:53,223]\u001b[0m Trial 8 finished with value: 0.7652356202578745 and parameters: {'n_estimators': 400, 'max_features': 'sqrt', 'max_depth': 8, 'min_samples_leaf': 32}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:56:02,264]\u001b[0m Trial 9 finished with value: 0.7617263470919725 and parameters: {'n_estimators': 900, 'max_features': 'log2', 'max_depth': 5, 'min_samples_leaf': 42}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:56:02,972]\u001b[0m Trial 10 finished with value: 0.7377543025930399 and parameters: {'n_estimators': 100, 'max_features': 'log2', 'max_depth': 1, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:56:12,545]\u001b[0m Trial 11 finished with value: 0.7716932432152761 and parameters: {'n_estimators': 700, 'max_features': 'log2', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:56:23,500]\u001b[0m Trial 12 finished with value: 0.7699579543584576 and parameters: {'n_estimators': 700, 'max_features': 'log2', 'max_depth': 12, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:56:32,776]\u001b[0m Trial 13 finished with value: 0.7702134472475743 and parameters: {'n_estimators': 700, 'max_features': 'log2', 'max_depth': 11, 'min_samples_leaf': 12}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:56:36,922]\u001b[0m Trial 14 finished with value: 0.7694818875417322 and parameters: {'n_estimators': 300, 'max_features': 'sqrt', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:56:43,433]\u001b[0m Trial 15 finished with value: 0.7718726944288006 and parameters: {'n_estimators': 500, 'max_features': 'log2', 'max_depth': 10, 'min_samples_leaf': 12}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:56:49,183]\u001b[0m Trial 16 finished with value: 0.7683226281101894 and parameters: {'n_estimators': 400, 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:56:50,080]\u001b[0m Trial 17 finished with value: 0.7548646371011739 and parameters: {'n_estimators': 100, 'max_features': 'log2', 'max_depth': 3, 'min_samples_leaf': 22}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:56:56,604]\u001b[0m Trial 18 finished with value: 0.7686810419049624 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_leaf': 12}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:57:00,399]\u001b[0m Trial 19 finished with value: 0.771383835668847 and parameters: {'n_estimators': 300, 'max_features': 'log2', 'max_depth': 13, 'min_samples_leaf': 22}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:57:06,151]\u001b[0m Trial 20 finished with value: 0.7711599861305636 and parameters: {'n_estimators': 400, 'max_features': 'sqrt', 'max_depth': 10, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.7726193016947084.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:57:15,683]\u001b[0m Trial 21 finished with value: 0.7732516098675379 and parameters: {'n_estimators': 700, 'max_features': 'log2', 'max_depth': 13, 'min_samples_leaf': 12}. Best is trial 21 with value: 0.7732516098675379.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:57:23,830]\u001b[0m Trial 22 finished with value: 0.7720528733578134 and parameters: {'n_estimators': 600, 'max_features': 'log2', 'max_depth': 13, 'min_samples_leaf': 12}. Best is trial 21 with value: 0.7732516098675379.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:57:33,288]\u001b[0m Trial 23 finished with value: 0.7735478062970803 and parameters: {'n_estimators': 700, 'max_features': 'log2', 'max_depth': 13, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:57:46,815]\u001b[0m Trial 24 finished with value: 0.7708438602103398 and parameters: {'n_estimators': 800, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:57:57,654]\u001b[0m Trial 25 finished with value: 0.7695845372764284 and parameters: {'n_estimators': 800, 'max_features': 'log2', 'max_depth': 13, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:58:06,476]\u001b[0m Trial 26 finished with value: 0.7686656675191993 and parameters: {'n_estimators': 700, 'max_features': 'log2', 'max_depth': 12, 'min_samples_leaf': 22}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:58:18,774]\u001b[0m Trial 27 finished with value: 0.7702411874005748 and parameters: {'n_estimators': 900, 'max_features': 'log2', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:58:27,789]\u001b[0m Trial 28 finished with value: 0.7700261774784206 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 11, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:58:37,749]\u001b[0m Trial 29 finished with value: 0.7709310140349276 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 12, 'min_samples_leaf': 22}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:58:47,306]\u001b[0m Trial 30 finished with value: 0.7721341475323924 and parameters: {'n_estimators': 700, 'max_features': 'log2', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:59:01,355]\u001b[0m Trial 31 finished with value: 0.7734146131926016 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:59:15,150]\u001b[0m Trial 32 finished with value: 0.7727747341936043 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:59:31,294]\u001b[0m Trial 33 finished with value: 0.7691227883591886 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 13, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:59:43,735]\u001b[0m Trial 34 finished with value: 0.7695330937521774 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 11, 'min_samples_leaf': 22}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 02:59:57,350]\u001b[0m Trial 35 finished with value: 0.7724342253621852 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:00:08,692]\u001b[0m Trial 36 finished with value: 0.7721016161277233 and parameters: {'n_estimators': 900, 'max_features': 'log2', 'max_depth': 9, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:00:20,805]\u001b[0m Trial 37 finished with value: 0.7711068111479197 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 32}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:00:33,226]\u001b[0m Trial 38 finished with value: 0.7711232771445621 and parameters: {'n_estimators': 900, 'max_features': 'log2', 'max_depth': 13, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:00:43,332]\u001b[0m Trial 39 finished with value: 0.770417225240696 and parameters: {'n_estimators': 800, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 22}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:00:59,887]\u001b[0m Trial 40 finished with value: 0.7697613230609974 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 14, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:01:07,937]\u001b[0m Trial 41 finished with value: 0.768509242659326 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 12, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:01:20,263]\u001b[0m Trial 42 finished with value: 0.7735207603788831 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:01:33,222]\u001b[0m Trial 43 finished with value: 0.7689731951276759 and parameters: {'n_estimators': 900, 'max_features': 'log2', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:01:44,774]\u001b[0m Trial 44 finished with value: 0.7693658801556824 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:01:56,755]\u001b[0m Trial 45 finished with value: 0.7711370039493305 and parameters: {'n_estimators': 900, 'max_features': 'log2', 'max_depth': 13, 'min_samples_leaf': 22}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:02:07,240]\u001b[0m Trial 46 finished with value: 0.7644873501388603 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 5, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:02:22,153]\u001b[0m Trial 47 finished with value: 0.7652652014344332 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 14, 'min_samples_leaf': 2}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:02:30,503]\u001b[0m Trial 48 finished with value: 0.7692149426269812 and parameters: {'n_estimators': 700, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 32}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:02:42,176]\u001b[0m Trial 49 finished with value: 0.7657964031464195 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 8, 'min_samples_leaf': 22}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:02:54,228]\u001b[0m Trial 50 finished with value: 0.7688263392433369 and parameters: {'n_estimators': 900, 'max_features': 'sqrt', 'max_depth': 12, 'min_samples_leaf': 12}. Best is trial 23 with value: 0.7735478062970803.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:03:01,071]\u001b[0m Trial 51 finished with value: 0.7759932305468273 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:03:07,907]\u001b[0m Trial 52 finished with value: 0.7702961131042996 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:03:13,422]\u001b[0m Trial 53 finished with value: 0.7716315197403449 and parameters: {'n_estimators': 400, 'max_features': 'sqrt', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:03:21,659]\u001b[0m Trial 54 finished with value: 0.7752207650109635 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:03:29,796]\u001b[0m Trial 55 finished with value: 0.7725995436482245 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 13, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:03:36,175]\u001b[0m Trial 56 finished with value: 0.7696819056589491 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 14, 'min_samples_leaf': 22}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:03:38,486]\u001b[0m Trial 57 finished with value: 0.7641029908838017 and parameters: {'n_estimators': 200, 'max_features': 'sqrt', 'max_depth': 11, 'min_samples_leaf': 42}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:03:44,513]\u001b[0m Trial 58 finished with value: 0.7702452844174402 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 7, 'min_samples_leaf': 2}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:03:49,208]\u001b[0m Trial 59 finished with value: 0.7332830790886915 and parameters: {'n_estimators': 700, 'max_features': 'sqrt', 'max_depth': 1, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:03:57,394]\u001b[0m Trial 60 finished with value: 0.7714172194254976 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 13, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:04:07,044]\u001b[0m Trial 61 finished with value: 0.7723202143811931 and parameters: {'n_estimators': 700, 'max_features': 'sqrt', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:04:18,016]\u001b[0m Trial 62 finished with value: 0.7705207592394355 and parameters: {'n_estimators': 800, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:04:26,249]\u001b[0m Trial 63 finished with value: 0.7686179791900828 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:04:31,738]\u001b[0m Trial 64 finished with value: 0.7710305688517461 and parameters: {'n_estimators': 400, 'max_features': 'log2', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:04:43,645]\u001b[0m Trial 65 finished with value: 0.7686223137215378 and parameters: {'n_estimators': 700, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 2}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:04:50,489]\u001b[0m Trial 66 finished with value: 0.7708306184488383 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:04:56,626]\u001b[0m Trial 67 finished with value: 0.7472966875113797 and parameters: {'n_estimators': 800, 'max_features': 'log2', 'max_depth': 2, 'min_samples_leaf': 22}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:05:08,808]\u001b[0m Trial 68 finished with value: 0.7721325504485029 and parameters: {'n_estimators': 900, 'max_features': 'log2', 'max_depth': 13, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:05:24,391]\u001b[0m Trial 69 finished with value: 0.769891453159661 and parameters: {'n_estimators': 1000, 'max_features': 'sqrt', 'max_depth': 12, 'min_samples_leaf': 2}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:05:32,532]\u001b[0m Trial 70 finished with value: 0.7695963637135012 and parameters: {'n_estimators': 600, 'max_features': 'log2', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:05:40,749]\u001b[0m Trial 71 finished with value: 0.7722119800105152 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:05:50,453]\u001b[0m Trial 72 finished with value: 0.7708928473967797 and parameters: {'n_estimators': 700, 'max_features': 'sqrt', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:05:57,294]\u001b[0m Trial 73 finished with value: 0.765921295588464 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:06:05,538]\u001b[0m Trial 74 finished with value: 0.7715797779895277 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:06:19,121]\u001b[0m Trial 75 finished with value: 0.7699629631718339 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 13, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:06:26,702]\u001b[0m Trial 76 finished with value: 0.7696354299881959 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 14, 'min_samples_leaf': 22}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:06:33,552]\u001b[0m Trial 77 finished with value: 0.7706528909007886 and parameters: {'n_estimators': 500, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:06:43,000]\u001b[0m Trial 78 finished with value: 0.7695371772412399 and parameters: {'n_estimators': 700, 'max_features': 'sqrt', 'max_depth': 13, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:06:59,499]\u001b[0m Trial 79 finished with value: 0.769675985149454 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 14, 'min_samples_leaf': 2}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:07:03,602]\u001b[0m Trial 80 finished with value: 0.762023446370601 and parameters: {'n_estimators': 400, 'max_features': 'log2', 'max_depth': 5, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:07:11,652]\u001b[0m Trial 81 finished with value: 0.7718348682445446 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 12, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:07:19,784]\u001b[0m Trial 82 finished with value: 0.770597550603784 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 13, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:07:29,404]\u001b[0m Trial 83 finished with value: 0.7698504936199944 and parameters: {'n_estimators': 700, 'max_features': 'sqrt', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:07:36,242]\u001b[0m Trial 84 finished with value: 0.7700830105521732 and parameters: {'n_estimators': 500, 'max_features': 'sqrt', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:07:46,297]\u001b[0m Trial 85 finished with value: 0.7716799361614192 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 13, 'min_samples_leaf': 22}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:07:54,252]\u001b[0m Trial 86 finished with value: 0.7702952639648577 and parameters: {'n_estimators': 600, 'max_features': 'sqrt', 'max_depth': 11, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:08:05,966]\u001b[0m Trial 87 finished with value: 0.7702077563593588 and parameters: {'n_estimators': 900, 'max_features': 'log2', 'max_depth': 9, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:08:19,379]\u001b[0m Trial 88 finished with value: 0.7681802133860086 and parameters: {'n_estimators': 1000, 'max_features': 'sqrt', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:08:24,035]\u001b[0m Trial 89 finished with value: 0.7568487857938452 and parameters: {'n_estimators': 500, 'max_features': 'log2', 'max_depth': 4, 'min_samples_leaf': 2}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:08:34,597]\u001b[0m Trial 90 finished with value: 0.7689268812635014 and parameters: {'n_estimators': 800, 'max_features': 'sqrt', 'max_depth': 12, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:08:47,986]\u001b[0m Trial 91 finished with value: 0.7694313993087649 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:09:01,512]\u001b[0m Trial 92 finished with value: 0.7734493464040723 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:09:13,654]\u001b[0m Trial 93 finished with value: 0.7696193057128926 and parameters: {'n_estimators': 900, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:09:27,117]\u001b[0m Trial 94 finished with value: 0.7721371395109676 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:09:40,603]\u001b[0m Trial 95 finished with value: 0.773368865613806 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:09:54,060]\u001b[0m Trial 96 finished with value: 0.7697640640975718 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:10:07,546]\u001b[0m Trial 97 finished with value: 0.7727809407697016 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:10:20,004]\u001b[0m Trial 98 finished with value: 0.7685477528635133 and parameters: {'n_estimators': 1000, 'max_features': 'log2', 'max_depth': 15, 'min_samples_leaf': 22}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n",
      "C:\\Users\\Alex2\\AppData\\Roaming\\Python\\Python39\\site-packages\\optuna\\distributions.py:683: UserWarning: The distribution is specified by [2, 50] and step=10, but the range is not divisible by `step`. It will be replaced by [2, 42].\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-10-05 03:10:32,091]\u001b[0m Trial 99 finished with value: 0.7695027876962006 and parameters: {'n_estimators': 900, 'max_features': 'log2', 'max_depth': 14, 'min_samples_leaf': 12}. Best is trial 51 with value: 0.7759932305468273.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "func = lambda trial: rf_obj(trial, x_train, y_train)\n",
    "study.optimize(func, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_scores.append(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.730731128849081, 0.7508930921270341, 0.7609686755514365, 0.7759932305468273]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<h2>Light GBM</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def objective(trial):\n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, df['transported'], test_size=0.25)\n",
    "    dtrain = lgbm.Dataset(train_x, label=train_y)\n",
    "    dtest = lgbm.Dataset(test_x, label=test_y)\n",
    "\n",
    "    param = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "    }\n",
    "\n",
    "    gbm = lgbm.train(param, dtrain, valid_sets=[dtrain, dtest])\n",
    "    preds = gbm.predict(test_x)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = roc_auc_score(test_y, pred_labels)\n",
    "    return accuracy\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_scores.append(study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBM</th>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "LogisticRegression 0.73\n",
       "KNN                0.75\n",
       "SVM                0.76\n",
       "RF                 0.78\n",
       "LGBM               0.80"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=model_scores, index=['LogisticRegression', 'KNN', 'SVM', 'RF', 'LGBM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1629\n",
      "[LightGBM] [Info] Number of data points in the train set: 5035, number of used features: 15\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Start training from score 0.523932\n",
      "[1]\ttraining's l2: 0.235748\tvalid_1's l2: 0.252627\n",
      "[2]\ttraining's l2: 0.222474\tvalid_1's l2: 0.220651\n",
      "[3]\ttraining's l2: 0.213081\tvalid_1's l2: 0.199954\n",
      "[4]\ttraining's l2: 0.203894\tvalid_1's l2: 0.181764\n",
      "[5]\ttraining's l2: 0.196313\tvalid_1's l2: 0.155355\n",
      "[6]\ttraining's l2: 0.190529\tvalid_1's l2: 0.131483\n",
      "[7]\ttraining's l2: 0.184359\tvalid_1's l2: 0.121427\n",
      "[8]\ttraining's l2: 0.180448\tvalid_1's l2: 0.118953\n",
      "[9]\ttraining's l2: 0.176335\tvalid_1's l2: 0.10718\n",
      "[10]\ttraining's l2: 0.172943\tvalid_1's l2: 0.0979851\n",
      "[11]\ttraining's l2: 0.170446\tvalid_1's l2: 0.0878547\n",
      "[12]\ttraining's l2: 0.167724\tvalid_1's l2: 0.07893\n",
      "[13]\ttraining's l2: 0.165609\tvalid_1's l2: 0.0840766\n",
      "[14]\ttraining's l2: 0.164055\tvalid_1's l2: 0.0890355\n",
      "[15]\ttraining's l2: 0.162068\tvalid_1's l2: 0.0833934\n",
      "[16]\ttraining's l2: 0.160657\tvalid_1's l2: 0.0800742\n",
      "[17]\ttraining's l2: 0.159146\tvalid_1's l2: 0.0745256\n",
      "[18]\ttraining's l2: 0.157952\tvalid_1's l2: 0.0667767\n",
      "[19]\ttraining's l2: 0.156891\tvalid_1's l2: 0.0618175\n",
      "[20]\ttraining's l2: 0.156117\tvalid_1's l2: 0.0650775\n",
      "[21]\ttraining's l2: 0.155243\tvalid_1's l2: 0.0604084\n",
      "[22]\ttraining's l2: 0.154327\tvalid_1's l2: 0.0595686\n",
      "[23]\ttraining's l2: 0.153732\tvalid_1's l2: 0.0564037\n",
      "[24]\ttraining's l2: 0.153115\tvalid_1's l2: 0.058381\n",
      "[25]\ttraining's l2: 0.152656\tvalid_1's l2: 0.0593103\n",
      "[26]\ttraining's l2: 0.152255\tvalid_1's l2: 0.0593307\n",
      "[27]\ttraining's l2: 0.151705\tvalid_1's l2: 0.0591767\n",
      "[28]\ttraining's l2: 0.151198\tvalid_1's l2: 0.0626657\n",
      "[29]\ttraining's l2: 0.150733\tvalid_1's l2: 0.0660463\n",
      "[30]\ttraining's l2: 0.150308\tvalid_1's l2: 0.0704348\n",
      "[31]\ttraining's l2: 0.149844\tvalid_1's l2: 0.0675362\n",
      "[32]\ttraining's l2: 0.149492\tvalid_1's l2: 0.0649055\n",
      "[33]\ttraining's l2: 0.149143\tvalid_1's l2: 0.0652354\n",
      "[34]\ttraining's l2: 0.148794\tvalid_1's l2: 0.0666893\n",
      "[35]\ttraining's l2: 0.148408\tvalid_1's l2: 0.0709678\n",
      "[36]\ttraining's l2: 0.148016\tvalid_1's l2: 0.0698254\n",
      "[37]\ttraining's l2: 0.147665\tvalid_1's l2: 0.0687906\n",
      "[38]\ttraining's l2: 0.147412\tvalid_1's l2: 0.0666739\n",
      "[39]\ttraining's l2: 0.147039\tvalid_1's l2: 0.0686212\n",
      "[40]\ttraining's l2: 0.14677\tvalid_1's l2: 0.0726362\n",
      "[41]\ttraining's l2: 0.146473\tvalid_1's l2: 0.0759211\n",
      "[42]\ttraining's l2: 0.146126\tvalid_1's l2: 0.078446\n",
      "[43]\ttraining's l2: 0.14586\tvalid_1's l2: 0.0785179\n",
      "[44]\ttraining's l2: 0.145634\tvalid_1's l2: 0.0824311\n",
      "[45]\ttraining's l2: 0.145377\tvalid_1's l2: 0.0846432\n",
      "[46]\ttraining's l2: 0.145173\tvalid_1's l2: 0.0875479\n",
      "[47]\ttraining's l2: 0.144864\tvalid_1's l2: 0.0842935\n",
      "[48]\ttraining's l2: 0.144598\tvalid_1's l2: 0.0812095\n",
      "[49]\ttraining's l2: 0.14441\tvalid_1's l2: 0.0806169\n",
      "[50]\ttraining's l2: 0.144241\tvalid_1's l2: 0.0832326\n",
      "[51]\ttraining's l2: 0.144006\tvalid_1's l2: 0.0868853\n",
      "[52]\ttraining's l2: 0.143823\tvalid_1's l2: 0.0828922\n",
      "[53]\ttraining's l2: 0.143595\tvalid_1's l2: 0.0833715\n",
      "[54]\ttraining's l2: 0.14338\tvalid_1's l2: 0.0873857\n",
      "[55]\ttraining's l2: 0.143174\tvalid_1's l2: 0.0896643\n",
      "[56]\ttraining's l2: 0.143029\tvalid_1's l2: 0.0920881\n",
      "[57]\ttraining's l2: 0.142819\tvalid_1's l2: 0.0857017\n",
      "[58]\ttraining's l2: 0.142583\tvalid_1's l2: 0.083083\n",
      "[59]\ttraining's l2: 0.14242\tvalid_1's l2: 0.0804424\n",
      "[60]\ttraining's l2: 0.142179\tvalid_1's l2: 0.0771949\n",
      "[61]\ttraining's l2: 0.142013\tvalid_1's l2: 0.0735724\n",
      "[62]\ttraining's l2: 0.141778\tvalid_1's l2: 0.0760895\n",
      "[63]\ttraining's l2: 0.141578\tvalid_1's l2: 0.0777645\n",
      "[64]\ttraining's l2: 0.141378\tvalid_1's l2: 0.0735513\n",
      "[65]\ttraining's l2: 0.14113\tvalid_1's l2: 0.0738937\n",
      "[66]\ttraining's l2: 0.140981\tvalid_1's l2: 0.0722146\n",
      "[67]\ttraining's l2: 0.140784\tvalid_1's l2: 0.0694845\n",
      "[68]\ttraining's l2: 0.140645\tvalid_1's l2: 0.072054\n",
      "[69]\ttraining's l2: 0.140448\tvalid_1's l2: 0.0699073\n",
      "[70]\ttraining's l2: 0.1402\tvalid_1's l2: 0.069595\n",
      "[71]\ttraining's l2: 0.139963\tvalid_1's l2: 0.0714474\n",
      "[72]\ttraining's l2: 0.139748\tvalid_1's l2: 0.0731354\n",
      "[73]\ttraining's l2: 0.139566\tvalid_1's l2: 0.0769494\n",
      "[74]\ttraining's l2: 0.13938\tvalid_1's l2: 0.0772263\n",
      "[75]\ttraining's l2: 0.139157\tvalid_1's l2: 0.0787629\n",
      "[76]\ttraining's l2: 0.138942\tvalid_1's l2: 0.0768524\n",
      "[77]\ttraining's l2: 0.138777\tvalid_1's l2: 0.0733858\n",
      "[78]\ttraining's l2: 0.138584\tvalid_1's l2: 0.076343\n",
      "[79]\ttraining's l2: 0.138413\tvalid_1's l2: 0.0762119\n",
      "[80]\ttraining's l2: 0.138247\tvalid_1's l2: 0.0772267\n",
      "[81]\ttraining's l2: 0.138123\tvalid_1's l2: 0.0798806\n",
      "[82]\ttraining's l2: 0.137947\tvalid_1's l2: 0.0778497\n",
      "[83]\ttraining's l2: 0.137795\tvalid_1's l2: 0.0763593\n",
      "[84]\ttraining's l2: 0.137596\tvalid_1's l2: 0.0794467\n",
      "[85]\ttraining's l2: 0.137414\tvalid_1's l2: 0.0786889\n",
      "[86]\ttraining's l2: 0.137279\tvalid_1's l2: 0.0814864\n",
      "[87]\ttraining's l2: 0.137091\tvalid_1's l2: 0.0789611\n",
      "[88]\ttraining's l2: 0.136887\tvalid_1's l2: 0.0839097\n",
      "[89]\ttraining's l2: 0.136723\tvalid_1's l2: 0.0815923\n",
      "[90]\ttraining's l2: 0.136592\tvalid_1's l2: 0.0795344\n",
      "[91]\ttraining's l2: 0.136429\tvalid_1's l2: 0.0830444\n",
      "[92]\ttraining's l2: 0.136246\tvalid_1's l2: 0.0862941\n",
      "[93]\ttraining's l2: 0.136047\tvalid_1's l2: 0.0818519\n",
      "[94]\ttraining's l2: 0.135901\tvalid_1's l2: 0.0876307\n",
      "[95]\ttraining's l2: 0.135751\tvalid_1's l2: 0.0899277\n",
      "[96]\ttraining's l2: 0.135627\tvalid_1's l2: 0.0911745\n",
      "[97]\ttraining's l2: 0.13544\tvalid_1's l2: 0.0870418\n",
      "[98]\ttraining's l2: 0.135277\tvalid_1's l2: 0.0890789\n",
      "[99]\ttraining's l2: 0.13512\tvalid_1's l2: 0.0938967\n",
      "[100]\ttraining's l2: 0.134983\tvalid_1's l2: 0.0911921\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "dtrain = lgbm.Dataset(x_train, label=y_train)\n",
    "dtest = lgbm.Dataset(data_test)\n",
    "model = lgbm.train(study.best_params, dtrain,  valid_sets=[dtrain, dtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3735"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(data_test)\n",
    "len(np.rint(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda_l1': 0.0005715022633567332,\n",
       " 'lambda_l2': 0.24797074796683777,\n",
       " 'num_leaves': 74,\n",
       " 'feature_fraction': 0.837113696668609,\n",
       " 'bagging_fraction': 0.8877717337699274,\n",
       " 'bagging_freq': 5,\n",
       " 'min_child_samples': 5}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
